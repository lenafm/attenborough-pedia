{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdQrD3xrUBHA"
   },
   "source": [
    "# Process subtitle text and extract part of speech considering pronoun resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jb45kxI-gJjc",
    "outputId": "b821aaf3-b1e3-4154-defe-f29f9fd2643e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting spacy==2.1.3\n",
      "  Downloading spacy-2.1.3-cp37-cp37m-manylinux1_x86_64.whl (27.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 27.7 MB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3) (2.0.6)\n",
      "Collecting jsonschema<3.0.0,>=2.6.0\n",
      "  Downloading jsonschema-2.6.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting blis<0.3.0,>=0.2.2\n",
      "  Downloading blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 48.4 MB/s \n",
      "\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n",
      "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
      "Collecting srsly<1.1.0,>=0.0.5\n",
      "  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
      "\u001b[K     |████████████████████████████████| 184 kB 48.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3) (0.9.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3) (1.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3) (1.21.6)\n",
      "Collecting thinc<7.1.0,>=7.0.2\n",
      "  Downloading thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 29.8 MB/s \n",
      "\u001b[?25hCollecting preshed<2.1.0,>=2.0.1\n",
      "  Downloading preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 464 kB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (3.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.3) (4.64.0)\n",
      "Installing collected packages: srsly, preshed, plac, blis, thinc, jsonschema, spacy\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 2.4.3\n",
      "    Uninstalling srsly-2.4.3:\n",
      "      Successfully uninstalled srsly-2.4.3\n",
      "  Attempting uninstall: preshed\n",
      "    Found existing installation: preshed 3.0.6\n",
      "    Uninstalling preshed-3.0.6:\n",
      "      Successfully uninstalled preshed-3.0.6\n",
      "  Attempting uninstall: blis\n",
      "    Found existing installation: blis 0.7.7\n",
      "    Uninstalling blis-0.7.7:\n",
      "      Successfully uninstalled blis-0.7.7\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.0.17\n",
      "    Uninstalling thinc-8.0.17:\n",
      "      Successfully uninstalled thinc-8.0.17\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.3.3\n",
      "    Uninstalling jsonschema-4.3.3:\n",
      "      Successfully uninstalled jsonschema-4.3.3\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.3.1\n",
      "    Uninstalling spacy-3.3.1:\n",
      "      Successfully uninstalled spacy-3.3.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "nbclient 0.6.4 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
      "nbclient 0.6.4 requires traitlets>=5.2.2, but you have traitlets 5.1.1 which is incompatible.\n",
      "en-core-web-sm 3.3.0 requires spacy<3.4.0,>=3.3.0.dev0, but you have spacy 2.1.3 which is incompatible.\n",
      "altair 4.2.0 requires jsonschema>=3.0, but you have jsonschema 2.6.0 which is incompatible.\u001b[0m\n",
      "Successfully installed blis-0.2.4 jsonschema-2.6.0 plac-0.9.6 preshed-2.0.1 spacy-2.1.3 srsly-1.0.5 thinc-7.0.8\n"
     ]
    }
   ],
   "source": [
    "# install spacy version 2.1.3 due to issues with the neural co ref library \n",
    "!pip install spacy==2.1.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGTox0s7gOOf",
    "outputId": "b47a908b-8595-482a-fbee-ff71b661db41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting neuralcoref\n",
      "  Downloading neuralcoref-4.0-cp37-cp37m-manylinux1_x86_64.whl (286 kB)\n",
      "\u001b[K     |████████████████████████████████| 286 kB 8.2 MB/s \n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading boto3-1.24.17-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 44.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.23.0)\n",
      "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (1.21.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2022.6.15)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
      "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.6)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.64.0)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 9.6 MB/s \n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.28.0,>=1.27.17\n",
      "  Downloading botocore-1.27.17-py3-none-any.whl (8.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.9 MB 56.7 MB/s \n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 68.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.17->boto3->neuralcoref) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.17->boto3->neuralcoref) (1.15.0)\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, neuralcoref\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.24.17 botocore-1.27.17 jmespath-1.0.1 neuralcoref-4.0 s3transfer-0.6.0 urllib3-1.25.11\n"
     ]
    }
   ],
   "source": [
    "# install the neural co ref\n",
    "!pip install neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46CyRvtBggsT",
    "outputId": "4567daeb-c5f0-4165-bb33-65fc6fc59d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting en_core_web_sm==2.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 9.3 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.1.0-py3-none-any.whl size=11074433 sha256=8ff7555acd3261f3e0fe1575c483eccf1ba8edd6f42a5691175f240cbb92ec51\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-2iz7c0pk/wheels/59/4f/8c/0dbaab09a776d1fa3740e9465078bfd903cc22f3985382b496\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 3.3.0\n",
      "    Uninstalling en-core-web-sm-3.3.0:\n",
      "      Successfully uninstalled en-core-web-sm-3.3.0\n",
      "Successfully installed en-core-web-sm-2.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# download the small english library\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EA7hxqjPg7nD"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import spacy\n",
    "import neuralcoref\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlD7lo8HgoFE",
    "outputId": "bdcb90f5-b314-49a0-804b-cf6ef9d3f3b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f2df77f8c50>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  load up the small model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# pop the neural co ref module into the pipeline\n",
    "\n",
    "neuralcoref.add_to_pipe(nlp,greedyness=0.45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MokgXcq4hJ7K",
    "outputId": "897f5574-e877-46dc-ad49-e14ee4d7521f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell Sam that he will have to leave without Arthur, as he is sick.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# quick test to check it works\n",
    "doc = nlp(\"Tell Sam that he will have to leave without Arthur, as he is sick.\")\n",
    "print(doc._.coref_resolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OB2Aes7XhL9D",
    "outputId": "80bfa9b8-0614-48bc-f500-5926cbb58f54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.srt\n",
      "8.srt\n",
      "5.srt\n",
      "1.srt\n",
      "9.srt\n",
      "3.srt\n",
      "6.srt\n",
      "10.srt\n",
      "2.srt\n",
      "7.srt\n",
      "Like all sparrows, they eat pretty well anything; insects, fruit and particularly seeds.\n",
      "They convert that diet into their own flesh, which is the richest of all foods: meat.\n",
      "So they themselves are much hunted.\n",
      "A falcon is also looking for a meal And it has one.\n",
      "Meat is such a rich food that a falcon need only kill once a day to sustain itself.\n",
      "So there's plenty of time for sitting around on the perch.\n",
      "Nice work if you can get it.\n",
      "But getting it is not necessarily all that easy.\n",
      "This hillside in\n",
      "Constructing spacy doc\n"
     ]
    }
   ],
   "source": [
    "# load the sub title contents into a single string.\n",
    "big_string = \"\"\n",
    "for filename in glob.glob('*.srt'):\n",
    "  print(filename)\n",
    "  with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "    for row in f.read().split(\"\\n\"):\n",
    "      if row == \"\" or row[0].isdigit():\n",
    "        continue\n",
    "      big_string = big_string + \" \" + row\n",
    "big_string = (\".\\n\").join([row.strip() for row in big_string.split(\".\")])\n",
    "\n",
    "print(big_string[:500])\n",
    "\n",
    "print(\"Constructing spacy doc\")\n",
    "\n",
    "doc = nlp(big_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43qGwfXnhlIR",
    "outputId": "bb072683-48e8-48c1-af64-6dbdd40921cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like all sparrows, they eat pretty well anything; insects, fruit and particularly seeds.\n",
      "all sparrows convert that diet into all sparrows own flesh, which is the richest of all foods: meat.\n",
      "So all sparrows themselves are much hunted.\n",
      "A falcon is also looking for a meal And A falcon has one.\n",
      "Meat is such a rich food that a falcon need only kill once a day to sustain a falcon.\n",
      "So there's plenty of time for sitting around on the perch.\n",
      "Nice work if you can get it.\n",
      "But getting it is not necessarily \n"
     ]
    }
   ],
   "source": [
    "# process the doc to replace the pronouns with the referenced nouns\n",
    "\n",
    "resolved_doc = doc._.coref_resolved\n",
    "print(resolved_doc[:500]) # first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "g4RUw37hhnpu"
   },
   "outputs": [],
   "source": [
    "f_out = open(\"subtitles_resolved.txt\", \"w\")\n",
    "f_out.write(resolved_doc)\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRwF9UgrnvMI",
    "outputId": "b8a6335b-3033-4ba4-be62-6ca041a74a78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"abbott's babbler\", 'babbler', \"abbott's booby\", 'booby', \"abbott's starling\"]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the list of bird names extracted from wikipedia\n",
    "\n",
    "bird_dict = {}\n",
    "birds = open(\"bird_list.txt\").read().lower().split(\"\\n\")\n",
    "for bird in birds:\n",
    "  # skip single letters A, B, C etc\n",
    "  if len(bird) == 1:\n",
    "    continue\n",
    "  bird_dict[bird] = True\n",
    "  # insert the last word too e..g yellow crested parrot > parrot\n",
    "  bird_dict[bird.split(\" \")[-1]] = True\n",
    "\n",
    "# check it has worked\n",
    "list(bird_dict.keys())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNFVsVTs8vZw"
   },
   "source": [
    "## Extract the nouns adj and proper nouns highlighting bird names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSz64d5siL0F",
    "outputId": "afee8dcb-f483-4444-eee3-a6282abd6947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Like all sparrows, they eat pretty well anything; insects, fruit and particularly seeds.', 'all sparrows convert that diet into all sparrows own flesh, which is the richest of all foods: meat.', 'So all sparrows themselves are much hunted.', 'A falcon is also looking for a meal And A falcon has one.', 'Meat is such a rich food that a falcon need only kill once a day to sustain a falcon.']\n"
     ]
    }
   ],
   "source": [
    "# split the subtitles into a set of rows for processing\n",
    "resolved_subtitles = open(\"subtitles_resolved.txt\").read()\n",
    "\n",
    "subtitle_rows = resolved_subtitles.split(\"\\n\")\n",
    "print(subtitle_rows[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "jVByp4eTm72I"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# dump the filtered resolved subtitles to a file\n",
    "\n",
    "valid_tokens = [\"NOUN\", 'ADJ', 'PROPN']\n",
    "\n",
    "lemma_tags = {\"NNS\", \"NNPS\"}\n",
    "\n",
    "birds = {}\n",
    "nouns = {}\n",
    "adjs = {}\n",
    "links = []\n",
    "filtered_subtitle_file = open(\"subtitles_resolved_filtered.txt\", \"w\")\n",
    "for row in subtitle_rows:\n",
    "  filtered_subtitle_file.write(row + \"\\n\")\n",
    "  row_doc = nlp(row)\n",
    "  row_tokens = []\n",
    "  for token in row_doc:\n",
    "    # depluralise nouns and proper nouns\n",
    "    singular = token.text\n",
    "    if token.tag_ in lemma_tags:\n",
    "      singular = token.lemma_\n",
    "    if token.pos_ not in valid_tokens:\n",
    "      continue\n",
    "    is_bird = token.pos_ == \"NOUN\" and singular in bird_dict\n",
    "    # print(singular + \"\\t\" + token.lemma_ + \"\\t\" + token.pos_ + \"\\t\" + str(is_bird) + \"\\n\")\n",
    "    if is_bird:\n",
    "      birds[singular] = birds.get(singular, 0) + 1\n",
    "    if token.pos_ == \"NOUN\":\n",
    "      nouns[singular] = nouns.get(singular, 0) + 1\n",
    "    if token.pos_ == \"ADJ\":\n",
    "      adjs[singular] = adjs.get(singular, 0) + 1\n",
    "    row_tokens.append(singular)\n",
    "    filtered_subtitle_file.write(singular + \"\\t\" + token.lemma_ + \"\\t\" + token.pos_ + \"\\t\" + str(is_bird) + \"\\n\")\n",
    "  row_tokens.sort()\n",
    "  for t1 in range(len(row_tokens)):\n",
    "    for t2 in range(t1 + 1, len(row_tokens)):\n",
    "      links.append([row_tokens[t1], row_tokens[t2]])\n",
    "  filtered_subtitle_file.write(\"\\n\")\n",
    "filtered_subtitle_file.close()\n",
    "\n",
    "# dump the nouns, adjs, birds, and links\n",
    "with open('nouns.json', 'w') as f:\n",
    "  f.write(json.dumps(nouns))\n",
    "\n",
    "with open('adjs.json', 'w') as f:\n",
    "  f.write(json.dumps(adjs))\n",
    "\n",
    "with open('birds.json', 'w') as f:\n",
    "  f.write(json.dumps(birds))\n",
    "\n",
    "links.sort()\n",
    "with open('links.json', 'w') as f:\n",
    "  f.write(json.dumps(links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "3Z-R76b3-Xv-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "L_GjhYWlOMUt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2rUUEwvQzT7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "spacy_ coreference_resolution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
